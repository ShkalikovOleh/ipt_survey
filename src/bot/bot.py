from argparse import ArgumentParser, Namespace
from collections.abc import Generator, Iterable, Mapping
import json
import os
import random
from typing import TypeVar
import dateutil.parser
import pandas as pd
import pytz
from telegram import Update
from telegram.ext import ContextTypes, Application, MessageHandler, filters
import datetime
import dateutil
import time


from src.teachers_db import Course, add_to_db, parse_teacher_json, role_to_str


T = TypeVar("T")


def batched(iterable: Iterable[T], n) -> Generator[T]:
    current_batch = []
    for item in iterable:
        current_batch.append(item)
        if len(current_batch) == n:
            yield current_batch
            current_batch = []
    if current_batch:
        yield current_batch


N_BATCH = 4
col2desc = {
    "–Ø–∫—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —Ä–∏—Å–∏ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞ (—Ç–∞–∫—ñ, —â–æ –º–æ–∂–Ω–∞ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–≤–∞—Ç–∏ —ñ–Ω—à–∏–º –≤–∏–∫–ª–∞–¥–∞—á–∞–º)?": "–Ø–∫—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —Ä–∏—Å–∏ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞?",
    "–ü–æ—Ä–∞–¥–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤. –©–æ –∫—Ä–∞—â–µ —Ä–æ–±–∏—Ç–∏ (—á–∏ –Ω–∞–≤–ø–∞–∫–∏, –Ω–µ —Ä–æ–±–∏—Ç–∏) –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –≥–∞—Ä–Ω–∏—Ö –≤—ñ–¥–Ω–æ—Å–∏–Ω —ñ–∑ –≤–∏–∫–ª–∞–¥–∞—á–µ–º, —è–∫—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞, –ø—Ä–æ —è–∫—ñ –≤–∏ –≤–≤–∞–∂–∞—î—Ç–µ –≤–∞—Ä—Ç–æ –∑–Ω–∞—Ç–∏ —Ç–∏–º, —Ö—Ç–æ –±—É–¥–µ —É –Ω—å–æ–≥–æ –≤—á–∏—Ç–∏—Å—å?": "–ü–æ—Ä–∞–¥–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤.",
    "–í—ñ–¥–∫—Ä–∏—Ç–∏–π –º—ñ–∫—Ä–æ—Ñ–æ–Ω. –£—Å–µ, —â–æ –≤–∏ —Ö–æ—á–µ—Ç–µ —Å–∫–∞–∑–∞—Ç–∏ –ø—Ä–æ –≤–∏–∫–ª–∞–¥–∞—á–∞, –∞–ª–µ —â–æ –Ω–µ –ø–æ–∫—Ä–∏–≤ –∂–æ–¥–µ–Ω —ñ–Ω—à–∏–π –ø—É–Ω–∫—Ç": "–í—ñ–¥–∫—Ä–∏—Ç–∏–π –º—ñ–∫—Ä–æ—Ñ–æ–Ω.",
}
col2emoji = {
    "–Ø–∫—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —Ä–∏—Å–∏ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞ (—Ç–∞–∫—ñ, —â–æ –º–æ–∂–Ω–∞ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–≤–∞—Ç–∏ —ñ–Ω—à–∏–º –≤–∏–∫–ª–∞–¥–∞—á–∞–º)?": "üíö",
    "–ü–æ—Ä–∞–¥–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤. –©–æ –∫—Ä–∞—â–µ —Ä–æ–±–∏—Ç–∏ (—á–∏ –Ω–∞–≤–ø–∞–∫–∏, –Ω–µ —Ä–æ–±–∏—Ç–∏) –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –≥–∞—Ä–Ω–∏—Ö –≤—ñ–¥–Ω–æ—Å–∏–Ω —ñ–∑ –≤–∏–∫–ª–∞–¥–∞—á–µ–º, —è–∫—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞, –ø—Ä–æ —è–∫—ñ –≤–∏ –≤–≤–∞–∂–∞—î—Ç–µ –≤–∞—Ä—Ç–æ –∑–Ω–∞—Ç–∏ —Ç–∏–º, —Ö—Ç–æ –±—É–¥–µ —É –Ω—å–æ–≥–æ –≤—á–∏—Ç–∏—Å—å?": "ü§ù",
    "–í—ñ–¥–∫—Ä–∏—Ç–∏–π –º—ñ–∫—Ä–æ—Ñ–æ–Ω. –£—Å–µ, —â–æ –≤–∏ —Ö–æ—á–µ—Ç–µ —Å–∫–∞–∑–∞—Ç–∏ –ø—Ä–æ –≤–∏–∫–ª–∞–¥–∞—á–∞, –∞–ª–µ —â–æ –Ω–µ –ø–æ–∫—Ä–∏–≤ –∂–æ–¥–µ–Ω —ñ–Ω—à–∏–π –ø—É–Ω–∫—Ç": "üì¢",
}
foul2stars = {
    "—Ö—É—è": "—Ö**",
    "–ø—ñ–¥–æ—Ä": "–ø****",
    "–Ω–∞—Ö—É–π": "–Ω****",
    "–±–ª—è": "–±**",
    "—Å—É–∫–∞": "—Å***",
}


def filter_foul_language(comment: str):
    for foul, star in foul2stars.items():
        comment = comment.replace(foul, star)
    return comment


async def post_next_teacher_results(
    context: ContextTypes.DEFAULT_TYPE,
    channel_id: str,
    viz_folder: str,
    teachers_db: dict[str, dict[str, Course]],
    df: pd.DataFrame,
    min_working_hour: int,
    max_working_hour: int,
):
    tmzinfo = pytz.timezone("Europe/Kyiv")
    curr_hour = datetime.datetime.now(tmzinfo).hour
    if curr_hour < min_working_hour or curr_hour >= max_working_hour:
        return

    shuffled_keys = df.index.to_list()
    random.Random(42).shuffle(shuffled_keys)

    if os.path.exists("pers_state.json"):
        with open("pers_state.json", "r") as pers_state_file:
            curr_pos = json.load(pers_state_file)["curr_pos"]
    else:
        curr_pos = 0

    if curr_pos > len(shuffled_keys):
        return

    teacher_name = shuffled_keys[curr_pos]

    caption = f"{teacher_name}\n"
    marks = "üîπüî∏"
    for idx, (course_name, course) in enumerate(teachers_db[teacher_name].items()):
        mark = marks[idx % 2]
        caption += f"\n{mark} {course_name} - {role_to_str[course.role]}"

    await context.bot.send_photo(
        chat_id=channel_id,
        photo=f"{viz_folder}/{teacher_name}.png",
        caption=caption,
        parse_mode="html",
    )

    with open("pers_state.json", "w") as pers_state_file:
        json.dump({"curr_pos": curr_pos + 1}, pers_state_file)


async def add_comments(
    update: Update, context: ContextTypes.DEFAULT_TYPE, df_results: pd.DataFrame
):
    name = update.message.caption.splitlines()[0]
    if name in df_results.index:
        data = df_results.loc[name]

        columns = [
            "–Ø–∫—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —Ä–∏—Å–∏ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞ (—Ç–∞–∫—ñ, —â–æ –º–æ–∂–Ω–∞ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–≤–∞—Ç–∏ —ñ–Ω—à–∏–º –≤–∏–∫–ª–∞–¥–∞—á–∞–º)?",
            "–ü–æ—Ä–∞–¥–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤. –©–æ –∫—Ä–∞—â–µ —Ä–æ–±–∏—Ç–∏ (—á–∏ –Ω–∞–≤–ø–∞–∫–∏, –Ω–µ —Ä–æ–±–∏—Ç–∏) –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –≥–∞—Ä–Ω–∏—Ö –≤—ñ–¥–Ω–æ—Å–∏–Ω —ñ–∑ –≤–∏–∫–ª–∞–¥–∞—á–µ–º, —è–∫—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ —î —É –≤–∏–∫–ª–∞–¥–∞—á–∞, –ø—Ä–æ —è–∫—ñ –≤–∏ –≤–≤–∞–∂–∞—î—Ç–µ –≤–∞—Ä—Ç–æ –∑–Ω–∞—Ç–∏ —Ç–∏–º, —Ö—Ç–æ –±—É–¥–µ —É –Ω—å–æ–≥–æ –≤—á–∏—Ç–∏—Å—å?",
            "–í—ñ–¥–∫—Ä–∏—Ç–∏–π –º—ñ–∫—Ä–æ—Ñ–æ–Ω. –£—Å–µ, —â–æ –≤–∏ —Ö–æ—á–µ—Ç–µ —Å–∫–∞–∑–∞—Ç–∏ –ø—Ä–æ –≤–∏–∫–ª–∞–¥–∞—á–∞, –∞–ª–µ —â–æ –Ω–µ –ø–æ–∫—Ä–∏–≤ –∂–æ–¥–µ–Ω —ñ–Ω—à–∏–π –ø—É–Ω–∫—Ç",
        ]

        for col in columns[:1]:
            await post_comment(update, context, data, col)

        for answers in batched(data["drawbacks_merged"], N_BATCH):
            comment = (
                "<blockquote>–Ø–∫—ñ –Ω–µ–¥–æ–ª—ñ–∫–∏ —î —É –≤–∏–∫–ª–∞–¥–∞–Ω–Ω—ñ?</blockquote>\n"
                "<blockquote>–Ø–∫—ñ —à–ª—è—Ö–∏ —ó—Ö –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –≤–∏ –±–∞—á–∏—Ç–µ?</blockquote>\n"
            )
            for answer in answers:
                critic, sugg = answer

                comment += "\n"
                if isinstance(critic, str):
                    comment += f"üî¥ {filter_foul_language(critic.rstrip())}\n"
                if isinstance(sugg, str):
                    comment += f"‚û°Ô∏è {filter_foul_language(sugg.rstrip())}\n"

            time.sleep(4)
            await context.bot.send_message(
                chat_id=update.message.chat_id,
                text=comment,
                reply_to_message_id=update.message.id,
                parse_mode="html",
            )

        for col in columns[1:]:
            await post_comment(update, context, data, col)


async def post_comment(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    data: Mapping[str, str],
    col: str,
):
    for answers in batched(data[col], N_BATCH):
        comment = f"<blockquote>{col2desc[col]}</blockquote>"
        for answer in answers:
            comment += f"\n\n{col2emoji[col]} {filter_foul_language(answer.rstrip())}"

        await context.bot.send_message(
            chat_id=update.message.chat_id,
            text=comment,
            reply_to_message_id=update.message.id,
            parse_mode="html",
        )
        time.sleep(4)  # No more than 20 message per minute


def run_bot(
    token: str,
    channel_id: str,
    teachers_db: dict[str, dict[str, Course]],
    df: pd.DataFrame,
    viz_folder: str,
    start_time: datetime.datetime,
    interval_min: int,
    min_working_hour: int,
    max_working_hour: int,
):
    application = (
        Application.builder().read_timeout(120).write_timeout(120).token(token).build()
    )
    job_queue = application.job_queue

    async def post_func(context):
        return await post_next_teacher_results(
            context,
            channel_id=channel_id,
            viz_folder=viz_folder,
            teachers_db=teachers_db,
            df=df,
            min_working_hour=min_working_hour,
            max_working_hour=max_working_hour,
        )

    async def comment_func(update, context):
        return await add_comments(update, context, df)

    timezone = start_time.tzinfo
    now = datetime.datetime.now(timezone)
    if now > start_time:
        first = 5
    else:
        first = int((start_time - now).total_seconds())

    job_queue.run_repeating(post_func, interval=interval_min * 60, first=first)

    channel_post_handler = MessageHandler(
        filters.User(777000),  # TG_ID
        comment_func,
    )
    application.add_handler(channel_post_handler)

    application.run_polling()


def load_teachers_db(files: list[str]):
    teacher_db = {}
    for path in files:
        _, _, data = parse_teacher_json(path)
        add_to_db(teacher_db, data)

    return teacher_db


def main(args: Namespace):
    with open(args.cfg_file) as cfg_file:
        cfg = json.load(cfg_file)

    start_time = dateutil.parser.parse(cfg["start_time"])

    df = pd.read_feather(cfg["survey_results"])
    teachers_db = load_teachers_db(cfg["teachers_info_files"])

    run_bot(
        cfg["TG_TOKEN"],
        cfg["channel_id"],
        teachers_db,
        df,
        cfg["viz_folder"],
        start_time,
        cfg["interval_min"],
        cfg["working_hours"]["min"],
        cfg["working_hours"]["max"],
    )


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("cfg_file", type=str)

    args = parser.parse_args()
    main(args)
